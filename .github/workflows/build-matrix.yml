name: Build Matrix

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

permissions:
  packages: write
  contents: read
  attestations: write
  id-token: write

jobs:
  prepare:
    runs-on: ubuntu-latest
    outputs:
      matrixInclude: ${{ steps.gen.outputs.matrixInclude }}
    steps:
      - id: gen
        env:
          SERVICES: |
            hello-world-elixir:elixir/Dockerfile
            hello-world-go:go/Dockerfile
            hello-world-node:node/Dockerfile
            hello-world-python:python/Dockerfile
            hello-world-rust:rust/Dockerfile
        run: |
          # Convert the services to JSON array
          # jq pipeline explanation:
          # 1. -R -s: Read input as raw strings and treat as single string
          # 2. split("\n"): Split the multi-line string into array of lines
          # 3. map(select(length > 0)): Filter out empty lines
          # 4. map(gsub("^\\s+|\\s+$"; "")): Remove leading/trailing whitespace (strip equivalent)
          # 5. map(split(":")): Split each line on colon into [name, path] arrays
          # 6. map({...}): Transform each [name, path] into JSON object with containerName and dockerfilePath
          # 7. -c: Output compact JSON (single line, no formatting)
          JSON=$(echo "$SERVICES" | jq -R -s -c 'split("\n") | map(select(length > 0)) | map(gsub("^\\s+|\\s+$"; "")) | map(split(":")) | map({"containerName": .[0], "dockerfilePath": .[1]})')
          echo "matrixInclude=$JSON" >> "$GITHUB_OUTPUT"

  build:
    runs-on: ubuntu-latest
    needs: prepare
    strategy:
      fail-fast: false
      matrix:
        include: ${{ fromJson(needs.prepare.outputs.matrixInclude) }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to GitHub Container Registry
      if: github.ref == 'refs/heads/main'
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata for Docker
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ghcr.io/${{ github.repository_owner }}/${{ matrix.containerName }}
        tags: |
          type=raw,value=latest
          type=sha

    - name: Build Docker image for testing
      id: build
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ${{ matrix.dockerfilePath }}
        platforms: linux/amd64
        push: false
        load: true  # Load image into local Docker daemon for testing
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Start container on port 8080
      run: |
        # Use the first tag from metadata for local testing (since image is loaded with tags, not digest)
        LOCAL_TAG=$(echo "${{ steps.meta.outputs.tags }}" | head -n1)
        docker run -d --name ${{ matrix.containerName }}-container -p 8080:8080 "$LOCAL_TAG"

    - name: Wait for container to be ready
      run: |
        timeout 30 bash -c 'until curl -f http://localhost:8080/ > /dev/null 2>&1; do sleep 2; done' || true

    - name: Test endpoint with cURL
      run: |
        # Capture both response body and status code in one request
        response=$(curl -s -w "%{http_code}" http://localhost:8080/)

        # Parse response: last 3 characters are the status code, rest is body
        response_code="${response: -3}"
        response_body="${response%???}"

        # Get only the first line and strip newlines to prevent markdown table formatting issues
        response_body_clean=$(echo "$response_body" | head -n 1 | tr -d '\n\r')

        echo "HTTP response code: $response_code"
        echo "HTTP response body: $response_body_clean"

        # Store test results in artifacts for summary job
        mkdir -p test-results
        echo "${{ matrix.containerName }},${{ matrix.dockerfilePath }},$response_code,$response_body_clean" > test-results/${{ matrix.containerName }}.csv

        if [ "$response_code" -eq 200 ]; then
          echo "✅ Test passed: Received HTTP 200 from /"
          echo "TEST_PASSED=true" >> $GITHUB_ENV
        else
          echo "❌ Test failed: Expected HTTP 200, got $response_code"
          echo "TEST_PASSED=false" >> $GITHUB_ENV
          exit 1
        fi

    - name: Generate and merge comprehensive SBOM
      if: env.TEST_PASSED == 'true' && github.ref == 'refs/heads/main'
      run: |
        echo "📋 Generating comprehensive SBOM with BuildKit + Microsoft sbom-tool..."
        
        # Create directories for SBOM processing
        mkdir -p sbom-output buildkit-sbom merged-sbom
        
        # 1. Extract BuildKit SBOM with all layers scanning
        echo "🔍 Step 1: Extracting BuildKit SBOM from image with all layers..."
        LOCAL_TAG=$(echo "${{ steps.meta.outputs.tags }}" | head -n1)
        
        # Use buildx imagetools to inspect and extract SBOM attestations
        docker buildx imagetools inspect --format '{{ json . }}' "$LOCAL_TAG" > image-manifest.json
        
        # Extract SBOM attestation if it exists
        if docker buildx imagetools inspect --format '{{range .Attestations}}{{if eq .Type "application/vnd.in-toto+json"}}{{.Data}}{{end}}{{end}}' "$LOCAL_TAG" > buildkit-sbom.json 2>/dev/null && [ -s buildkit-sbom.json ]; then
          echo "✅ Found BuildKit SBOM attestation"
          # Try to extract the actual SBOM from the attestation
          if jq -r '.predicate.Data // .predicate' buildkit-sbom.json > buildkit-sbom/buildkit.spdx.json 2>/dev/null && [ -s buildkit-sbom/buildkit.spdx.json ]; then
            echo "✅ Extracted BuildKit SBOM data"
          else
            echo "⚠️  BuildKit SBOM attestation found but couldn't extract SPDX data"
            echo '{"packages": [], "note": "BuildKit SBOM attestation exists but format not extractable"}' > buildkit-sbom/buildkit.spdx.json
          fi
        else
          echo "⚠️  No BuildKit SBOM attestation found in image"
          echo '{"packages": [], "note": "No BuildKit SBOM available"}' > buildkit-sbom/buildkit.spdx.json
        fi
        
        # 2. Generate Microsoft SBOM
        echo "🔍 Step 2: Generating Microsoft SBOM for source code..."
        
        # Download and install Microsoft's official sbom-tool
        curl -Lo sbom-tool https://github.com/microsoft/sbom-tool/releases/latest/download/sbom-tool-linux-x64
        chmod +x sbom-tool
        
        # Extract the directory path from the dockerfile path for targeted scanning
        DOCKERFILE_DIR=$(dirname "${{ matrix.dockerfilePath }}")
        
        echo "🔍 Scanning $DOCKERFILE_DIR for source components..."
        
        # Generate SBOM in SPDX 2.2 format, scanning only the relevant directory
        ./sbom-tool generate \
          -b "$DOCKERFILE_DIR" \
          -bc "$DOCKERFILE_DIR" \
          -pn "${{ matrix.containerName }}" \
          -pv "sha-${{ github.sha }}" \
          -ps "${{ github.repository_owner }}" \
          -nsb "https://github.com/${{ github.repository_owner }}" \
          -mi SPDX:2.2 \
          -m sbom-output \
          -V Warning || {
            echo "⚠️  Microsoft SBOM generation completed with warnings"
            # Ensure the SBOM file exists even if minimal
            if [ ! -f "sbom-output/_manifest/spdx_2.2/manifest.spdx.json" ]; then
              echo "📝 Creating minimal Microsoft SBOM as fallback..."
              mkdir -p sbom-output/_manifest/spdx_2.2
              cat > sbom-output/_manifest/spdx_2.2/manifest.spdx.json << EOF
        {
          "spdxVersion": "SPDX-2.2",
          "dataLicense": "CC0-1.0",
          "SPDXID": "SPDXRef-DOCUMENT",
          "name": "${{ matrix.containerName }}",
          "documentNamespace": "https://github.com/${{ github.repository_owner }}/${{ matrix.containerName }}/sha-${{ github.sha }}",
          "creationInfo": {
            "created": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "creators": ["Tool: Microsoft.Sbom.Tool", "Organization: ${{ github.repository_owner }}"]
          },
          "packages": [],
          "relationships": []
        }
        EOF
            fi
          }
        
        # 3. Merge SBOMs
        echo "🔗 Step 3: Merging BuildKit and Microsoft SBOM results..."
        
        # Also check for native BuildKit SBOM output
        if [ -f "buildkit-native-sbom.spdx.json" ]; then
          echo "✅ Found native BuildKit SBOM output"
          cp buildkit-native-sbom.spdx.json buildkit-sbom/buildkit-native.spdx.json
        fi
        
        # Create a comprehensive merged SBOM
        cat > merge-sboms.py << 'EOF'
        import json
        import sys
        from datetime import datetime
        import os
        
        def load_json_safe(filepath):
            try:
                with open(filepath, 'r') as f:
                    content = f.read().strip()
                    if not content:
                        return {"packages": []}
                    return json.loads(content)
            except Exception as e:
                print(f"Warning: Could not load {filepath}: {e}")
                return {"packages": []}
        
        # Load all available SBOMs
        ms_sbom = load_json_safe('sbom-output/_manifest/spdx_2.2/manifest.spdx.json')
        buildkit_attestation_sbom = load_json_safe('buildkit-sbom/buildkit.spdx.json')
        buildkit_native_sbom = load_json_safe('buildkit-sbom/buildkit-native.spdx.json')
        
        # Create merged SBOM structure
        merged = {
            "spdxVersion": "SPDX-2.2",
            "dataLicense": "CC0-1.0",
            "SPDXID": "SPDXRef-DOCUMENT",
            "name": "${{ matrix.containerName }}-comprehensive",
            "documentNamespace": f"https://github.com/${{ github.repository_owner }}/${{ matrix.containerName }}/comprehensive-sha-${{ github.sha }}",
            "creationInfo": {
                "created": datetime.utcnow().isoformat() + "Z",
                "creators": [
                    "Tool: Microsoft.Sbom.Tool-v2.2.7", 
                    "Tool: Docker.BuildKit-v0.12+", 
                    "Tool: Docker.BuildKit.Native-SBOM",
                    "Organization: ${{ github.repository_owner }}",
                    "Tool: Custom.Comprehensive.SBOM.Merger-v1.0"
                ]
            },
            "packages": [],
            "relationships": [],
            "annotations": [
                {
                    "annotationType": "OTHER",
                    "annotator": "Tool: Custom.Comprehensive.SBOM.Merger",
                    "annotationDate": datetime.utcnow().isoformat() + "Z",
                    "annotationComment": "Comprehensive SBOM merging: (1) Microsoft SBOM Tool for source code analysis, (2) Docker BuildKit attestation SBOM for container layer analysis, (3) Docker BuildKit native SBOM for build-time analysis. This provides complete supply chain visibility."
                }
            ]
        }
        
        # Function to add packages with deduplication
        def add_packages(sbom_data, source_name, prefix):
            packages = sbom_data.get("packages", [])
            added_count = 0
            
            for pkg in packages:
                if isinstance(pkg, dict) and pkg.get("name"):
                    # Create a unique identifier for deduplication
                    pkg_id = f"{pkg.get('name', 'unknown')}-{pkg.get('versionInfo', 'unknown')}"
                    
                    # Check if package already exists
                    existing = any(
                        p.get("name") == pkg.get("name") and 
                        p.get("versionInfo") == pkg.get("versionInfo")
                        for p in merged["packages"]
                    )
                    
                    if not existing:
                        pkg["SPDXID"] = f"SPDXRef-{prefix}-{len(merged['packages'])}"
                        pkg["_source"] = source_name
                        pkg["_analysisType"] = {
                            "Microsoft.Sbom.Tool": "source-code-analysis",
                            "Docker.BuildKit.Attestation": "container-layer-analysis", 
                            "Docker.BuildKit.Native": "build-time-analysis"
                        }.get(source_name, "unknown")
                        merged["packages"].append(pkg)
                        added_count += 1
                    
            return added_count
        
        # Add packages from all sources with deduplication
        ms_count = add_packages(ms_sbom, "Microsoft.Sbom.Tool", "MS")
        bk_att_count = add_packages(buildkit_attestation_sbom, "Docker.BuildKit.Attestation", "BK-ATT")
        bk_native_count = add_packages(buildkit_native_sbom, "Docker.BuildKit.Native", "BK-NAT")
        
        # Add relationships from all SBOMs
        merged["relationships"].extend(ms_sbom.get("relationships", []))
        merged["relationships"].extend(buildkit_attestation_sbom.get("relationships", []))
        merged["relationships"].extend(buildkit_native_sbom.get("relationships", []))
        
        # Add comprehensive summary information
        merged["_comprehensiveSummary"] = {
            "totalUniquePackages": len(merged["packages"]),
            "sourceBreakdown": {
                "microsoftSbomTool": {
                    "packagesAdded": ms_count,
                    "analysisType": "source-code-dependencies",
                    "scanTarget": "application-source-directory"
                },
                "buildkitAttestation": {
                    "packagesAdded": bk_att_count,
                    "analysisType": "container-layer-packages",
                    "scanTarget": "final-container-image"
                },
                "buildkitNative": {
                    "packagesAdded": bk_native_count,
                    "analysisType": "build-time-dependencies",
                    "scanTarget": "docker-build-context"
                }
            },
            "mergingStrategy": "union-with-deduplication-and-source-attribution",
            "coverageAreas": [
                "source-code-dependencies",
                "container-runtime-packages", 
                "build-time-artifacts",
                "base-image-components"
            ]
        }
        
        # Save merged SBOM
        with open('merged-sbom/comprehensive.spdx.json', 'w') as f:
            json.dump(merged, f, indent=2)
            
        print(f"✅ Comprehensive SBOM created with {len(merged['packages'])} unique packages")
        print(f"   📦 Microsoft SBOM Tool: {ms_count} packages (source analysis)")
        print(f"   📦 BuildKit Attestation: {bk_att_count} packages (container layers)")  
        print(f"   📦 BuildKit Native: {bk_native_count} packages (build-time)")
        print(f"   🔗 Total relationships: {len(merged['relationships'])}")
        EOF
        
        python3 merge-sboms.py
        
        # Use the comprehensive merged SBOM for attestation
        cp merged-sbom/comprehensive.spdx.json sbom.spdx.json
        
        echo "✅ Comprehensive multi-source SBOM generated and merged successfully"
        echo "📊 Final SBOM Statistics:"
        jq -r '._comprehensiveSummary.sourceBreakdown | to_entries[] | "  \(.key): \(.value.packagesAdded) packages (\(.value.analysisType))"' sbom.spdx.json

    - name: Build and push image with comprehensive attestations
      id: build-push
      if: env.TEST_PASSED == 'true' && github.ref == 'refs/heads/main'
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ${{ matrix.dockerfilePath }}
        platforms: linux/amd64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        # Enable comprehensive attestations for supply chain security
        provenance: true
        sbom: true
        # Configure SBOM to scan all layers comprehensively
        build-args: |
          BUILDKIT_SBOM_SCAN_STAGE=true
          BUILDKIT_SBOM_SCAN_CONTEXT=true
        outputs: |
          type=image,push=true
          type=sbom,dest=./buildkit-native-sbom.spdx.json

    - name: Generate attestations
      if: env.TEST_PASSED == 'true' && github.ref == 'refs/heads/main'
      run: |
        echo "🔐 Generating security attestations for ${{ matrix.containerName }}..."
        echo "   → Build provenance attestation"
        echo "   → SBOM attestation"
        echo "   (Individual attestation outputs suppressed - see combined summary)"

    - name: Generate GitHub artifact attestation
      id: build-attestation
      if: env.TEST_PASSED == 'true' && github.ref == 'refs/heads/main'
      uses: actions/attest-build-provenance@v2
      with:
        subject-name: ghcr.io/${{ github.repository_owner }}/${{ matrix.containerName }}
        subject-digest: ${{ steps.build-push.outputs.digest }}
        push-to-registry: true
        show-summary: false
      env:
        ACTIONS_STEP_DEBUG: false
        RUNNER_DEBUG: 0

    - name: Generate SBOM attestation
      id: sbom-attestation
      if: env.TEST_PASSED == 'true' && github.ref == 'refs/heads/main'
      uses: actions/attest-sbom@v2
      with:
        subject-name: ghcr.io/${{ github.repository_owner }}/${{ matrix.containerName }}
        subject-digest: ${{ steps.build-push.outputs.digest }}
        sbom-path: sbom.spdx.json
        push-to-registry: true
        show-summary: false
      env:
        ACTIONS_STEP_DEBUG: false
        RUNNER_DEBUG: 0

    - name: Store attestation results
      if: always() && env.TEST_PASSED == 'true' && github.ref == 'refs/heads/main'
      run: |
        echo "📝 Storing attestation results for summary..."
        mkdir -p attestation-results
        
        # Check if attestations were successful and capture URLs
        build_status="❌ Failed"
        sbom_status="❌ Failed"
        build_url=""
        sbom_url=""
        
        if [[ "${{ steps.build-attestation.outcome }}" == "success" ]]; then
          build_status="✅ Signed"
          build_url="${{ steps.build-attestation.outputs.attestation-url }}"
        fi
        
        if [[ "${{ steps.sbom-attestation.outcome }}" == "success" ]]; then
          sbom_status="✅ Signed"
          sbom_url="${{ steps.sbom-attestation.outputs.attestation-url }}"
        fi
        
        echo "${{ matrix.containerName }},${{ matrix.dockerfilePath }},${{ steps.build-push.outputs.digest }},$build_status,$sbom_status,$build_url,$sbom_url" > attestation-results/${{ matrix.containerName }}.csv
        echo "✅ Attestation results stored for ${{ matrix.containerName }}"

    - name: Upload test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.containerName }}
        path: test-results/
        retention-days: 1

    - name: Upload attestation results
      if: env.TEST_PASSED == 'true' && github.ref == 'refs/heads/main'
      uses: actions/upload-artifact@v4
      with:
        name: attestation-results-${{ matrix.containerName }}
        path: attestation-results/
        retention-days: 1

    - name: Package visibility information
      if: env.TEST_PASSED == 'true' && github.ref == 'refs/heads/main'
      run: |
        echo "📦 Container package published: ghcr.io/${{ github.repository_owner }}/${{ matrix.containerName }}"
        echo "🔒 Package is currently private by default"
        echo ""
        echo "To make it public:"
        echo "1. Go to https://github.com/${{ github.repository_owner }}?tab=packages"
        echo "2. Click on '${{ matrix.containerName }}' package"
        echo "3. Go to Package settings (⚙️) → Change visibility → Public"
        echo ""
        echo "Or use the GitHub CLI:"
        echo "gh api -X PATCH /user/packages/container/${{ matrix.containerName }} -f visibility=public"

    - name: Cleanup container
      if: always()
      run: |
        docker stop ${{ matrix.containerName }}-container || true
        docker rm ${{ matrix.containerName }}-container || true

  summary:
    runs-on: ubuntu-latest
    needs: build
    if: always()

    steps:
    - name: Download all test results
      uses: actions/download-artifact@v4
      with:
        pattern: test-results-*
        path: all-results
        merge-multiple: true

    - name: Download all attestation results
      uses: actions/download-artifact@v4
      with:
        pattern: attestation-results-*
        path: all-attestations
        merge-multiple: true

    - name: Create combined summary
      run: |
        echo "# 🚀 Container Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Container Name | Dockerfile Path | Status Code | Response Body | Test Result |" >> $GITHUB_STEP_SUMMARY
        echo "|----------------|-----------------|-------------|---------------|-------------|" >> $GITHUB_STEP_SUMMARY

        for file in all-results/*.csv; do
          if [ -f "$file" ]; then
            IFS=',' read -r container dockerfile_path status_code response_body < "$file"
            if [ "$status_code" -eq 200 ]; then
              result="✅ PASSED"
            else
              result="❌ FAILED"
            fi
            echo "| **$container** | \`$dockerfile_path\` | \`$status_code\` | \`$response_body\` | $result |" >> $GITHUB_STEP_SUMMARY
          fi
        done

        echo "" >> $GITHUB_STEP_SUMMARY

        # Add registry push information for main builds
        if [[ "$GITHUB_REF" == "refs/heads/main" ]]; then
          echo "## 📦 Published Container Images" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The following images were pushed to GitHub Container Registry:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          for file in all-results/*.csv; do
            if [ -f "$file" ]; then
              IFS=',' read -r container dockerfile_path status_code response_body < "$file"
              if [ "$status_code" -eq 200 ]; then
                echo "- 📦 \`ghcr.io/${{ github.repository_owner }}/$container:latest\`" >> $GITHUB_STEP_SUMMARY
                echo "- 📦 \`ghcr.io/${{ github.repository_owner }}/$container:sha-${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
              fi
            fi
          done
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "> 💡 **Pull images:** \`docker pull ghcr.io/${{ github.repository_owner }}/IMAGE_NAME:latest\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Add comprehensive attestations summary
          echo "## 🔐 Security Attestations Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -d "all-attestations" ] && [ "$(ls -A all-attestations 2>/dev/null)" ]; then
            echo "| Container | Dockerfile | Image Digest | Build Provenance | SBOM Attestation | Verification |" >> $GITHUB_STEP_SUMMARY
            echo "|-----------|------------|-------------|------------------|------------------|--------------|" >> $GITHUB_STEP_SUMMARY
            
            for file in all-attestations/*.csv; do
              if [ -f "$file" ]; then
                IFS=',' read -r container dockerfile_path digest build_status sbom_status build_url sbom_url < "$file"
                short_digest="${digest#sha256:}"
                short_digest="${short_digest:0:12}"
                
                # Create hyperlinked status for build provenance
                if [[ "$build_status" == "✅ Signed" && -n "$build_url" ]]; then
                  build_display="[✅ Signed]($build_url)"
                else
                  build_display="$build_status"
                fi
                
                # Create hyperlinked status for SBOM
                if [[ "$sbom_status" == "✅ Signed" && -n "$sbom_url" ]]; then
                  sbom_display="[✅ Signed]($sbom_url)"
                else
                  sbom_display="$sbom_status"
                fi
                
                echo "| **$container** | \`$dockerfile_path\` | \`$short_digest...\` | $build_display | $sbom_display | \`gh attestation verify oci://ghcr.io/${{ github.repository_owner }}/$container:latest\` |" >> $GITHUB_STEP_SUMMARY
              fi
            done
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### 🛡️ Attestation Details" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "All published images include comprehensive supply chain security attestations:" >> $GITHUB_STEP_SUMMARY
            echo "- **Build Provenance**: GitHub artifact attestations establishing build source and environment" >> $GITHUB_STEP_SUMMARY
            echo "- **Comprehensive SBOM**: Multi-source Software Bill of Materials in SPDX format including:" >> $GITHUB_STEP_SUMMARY
            echo "  - 🔍 **Source Code Analysis** (Microsoft SBOM Tool): Application dependencies and source components" >> $GITHUB_STEP_SUMMARY
            echo "  - 📦 **Container Layer Analysis** (BuildKit Attestation): Runtime packages and base image components" >> $GITHUB_STEP_SUMMARY
            echo "  - 🔧 **Build-time Analysis** (BuildKit Native): Build dependencies and intermediate artifacts" >> $GITHUB_STEP_SUMMARY
            echo "- **Docker Attestations**: Native Docker BuildKit provenance with all-layer scanning enabled" >> $GITHUB_STEP_SUMMARY
            echo "- **SLSA Compliance**: Meets SLSA v1.0 Build Level 2+ requirements with comprehensive artifact tracking" >> $GITHUB_STEP_SUMMARY
          else
            echo "No attestations were generated (likely due to test failures or non-main branch)." >> $GITHUB_STEP_SUMMARY
          fi
        fi

        echo "" >> $GITHUB_STEP_SUMMARY

        # Container package visibility information for main branch builds
        if [[ "$GITHUB_REF" == "refs/heads/main" ]]; then
          echo "## 📦 Published Container Images" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The following images were pushed to GitHub Container Registry:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          for file in all-results/*.csv; do
            if [ -f "$file" ]; then
              IFS=',' read -r container dockerfile_path status_code response_body < "$file"
              if [ "$status_code" -eq 200 ]; then
                echo "- 📦 \`ghcr.io/${{ github.repository_owner }}/$container:latest\`" >> $GITHUB_STEP_SUMMARY
                echo "- 📦 \`ghcr.io/${{ github.repository_owner }}/$container:sha-${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
              fi
            fi
          done
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### 🔒 Making Packages Public" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Container packages are **private by default**. To make them public:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Option 1: Via GitHub Web Interface**" >> $GITHUB_STEP_SUMMARY
          echo "1. Go to [Your Packages](https://github.com/${{ github.repository_owner }}?tab=packages)" >> $GITHUB_STEP_SUMMARY
          echo "2. Click on a package name" >> $GITHUB_STEP_SUMMARY
          echo "3. Go to Package settings ⚙️ → Change visibility → Public" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Option 2: Via GitHub CLI**" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`bash" >> $GITHUB_STEP_SUMMARY
          echo "gh api -X PATCH /user/packages/container/PACKAGE_NAME -f visibility=public" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Then you can pull images:**" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`bash" >> $GITHUB_STEP_SUMMARY
          echo "docker pull ghcr.io/${{ github.repository_owner }}/hello-world-go:latest" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        fi
